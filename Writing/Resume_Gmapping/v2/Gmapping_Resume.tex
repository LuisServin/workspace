\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage[mathscr]{euscript}

% this is to make it look like a word document.
\usepackage[tmargin=0.98in,bmargin=0.98in,lmargin=1.18in,rmargin=1.18in]{geometry}

% package needed to draw a frame for a text
\usepackage[linewidth=1pt]{mdframed}

\title{Técnicas de optimización para mapeo basado en rejillas utilizando un filtro de partículas de tipo Rao-Blackwell \\ \large{G-mapping}}
\date{\today}
\author{Luis Servín\\ Taller TRA, Universidad Nacional Autónoma de México}

\begin{document}

\maketitle

\section*{Resumen}

El problema del "Localización y Mapeo Simultáneo", \textbf{SLAM} por sus siglas en inglés, ha sido ámpliamente estudiado en el campo de la robótica móvil, una de las estrategias utilizadas para abordarlo es el \emph{filtro de partículas tipo Rao-Blackwell}. Esta hace uso de un filtro de partículas en el cual cada partícula contiene su propio mapa del ambiente, además propone una distribución de probabilidad mejorada en comparación a las utilizadas comúnmente, tomando en cuenta tanto el movimiento del robot como la observación mas reciente. Los resultados experimentales realizados en ambientes reales, grandes, cerrados y/o abiertos buscan demostrar las ventajas de esta propuesta contra otras opciones.



%-------------------------------------------
% SECTION I: INTRODUCCIÓN
%-------------------------------------------



\section{Introducción}

Tener la habilidad de construir una representación del ambiente es una de las tareas fundamentales en un robot móvil real. En la literatura, el problema de mapeo, a través de una plataforma móvil, es usualmente conocido como "Localización y Mapeo Simultáneos", o \textbf{SLAM} por sus siglas en ingles (Simultaneous Localization and Mapping).

Dentro de los principales problemas que presentan las estrategias tipo Rao-Blackwell es su complejidad medida en el número de partículas requeridas para construir un mapa suficientemente preciso. Además puede presentarse el efecto \emph{particle depleton}, durante el paso de remuestreo (resampling), en el cual partículas útiles o con información valiosa son eliminadas de manera aleatoria.

Por lo anterior las dos estrategias implementadas en el enfoque propuesto son:

\begin{enumerate}

	\item Proponer una distribución de probabilidad que considere las precisión obtenida por los sensores del robot, y con ella obtener un mejor conjunto de partículas.

	\item Técnica de remuestreo (resampling) adaptable, que reduzca la cantidad de partículas necesarias, y con ello evitar que se presente el fenómeno de \emph{particle depletion}.

\end{enumerate}

Dicha distribución es obtenida a partir de combinar la información obtenida por medio de la odometría, con la posición de una partícula resultante de un proceso de emparejamiento de puntos (\emph{scan matching}). Con lo cual se logran dos efectos importantes:

\begin{itemize}

\item El mapa es mas preciso, gracias a que se incorpora la observación mas reciente obtenida por el láser al mapa de manera individual, después de considerar su efecto en la posición del robot.

\item El paso de remuestreo se realiza solamente cuando es necesario graicas a la estrategia de remuestreo adaptable aplicada.

\end{itemize}



%-------------------------------------------
% SECTION I: DESARROLLO DE LA ESTRATEGIA
%-------------------------------------------



\section{Mapeo a través de un filtro de partículas Rao-Blackwell}

La idea central de aplicar un filtro de partículas de tipo Rao-Blackwell al problema de SLAM es estimar la probabilidad conjunta posterior $ p(x_{1:t},m | z_{1:t},u_{1:t-1}) $ sobre el mapa $ m $ y la trayectoria del robot $ x_{1:t} = x_{1},...,x_{t} $, dadas las observaciones $ z_{1:t} = z_{1},...,z_{t} $ y los datos de odometría $ u_{1:t-1} = u_{1},...,u_{t-1} $. Por lo tanto obtenemos que el filtro de partículas Rao-Blackwell aplicado al problema de SLAM queda de la forma:

\begin{equation}
	p(x_{1:t},m | z_{1:t},u_{1:t-1}) = 
		p(m | x_{1:t}, z_{1:t}) \cdot p(x_{1:t} | z_{1:t},u_{1:t-1})
\end{equation}

Como primer paso se estima solamente la trayectoria, enseguida se calcula el mapa, dada la trayectoria obtenida.

$ p(m | x_{1:t}, z_{1:t}) $ puede ser calculada de manera analítica \cite{moravec1988sensor}, dado e conocimiento que se tiene de $ x_{1:t} $ y $ z_{1:t} $. En el caso de $ p(x_{1:t} | z_{1:t},u_{1:t-1} $ se puede aplicar un filtro de partículas. En éste cada partícula representa una trayectoria potencial, además de que se le asocia un mapa individual. Este mapa se construye con base en las observaciones $z_{t:1}$, la trayectoria $x_{t:1}$ representada para cada partícula.

El algoritmo de \textbf{Remuestreo Basado en la Importancia de la Muestra}, o \textbf{SIR (Sampling Importance Resampling)} por sus siglas en ingles, procesa de manera incremental la información obtenida por las lecturas del láser y los datos de odometría tan pronto como estén disponibles. El algoritmo se puede dividir en los siguientes pasos:

\begin{mdframed}

\begin{enumerate}

	\item \textbf{Muestreo} (Sampling): La futura generación de partículas {$ x_{t}^{(i)} $} se obtiene de la generación actual {$ x_{t-1}^{(i)} $} a través de realizar un muestreo sobre una distribución $ \pi $ propuesta

	\item \textbf{Ponderación de importancia} (Importance Weighting): Se asigna una ponderación de importancia a cada partícula basada en el principio de \emph{Importancia de muestreo}:

	\begin{equation}
	\label{eq:weigth}
		w_{t}^{(i)} = 
			\frac{ p( x_{1:t}^{(i)} | z_{1:t}, u_{1:t-1} ) }
				{ \pi ( x_{1:t}^{(i)} | z_{1:t}, u_{1:t-1} ) }
	\end{equation}
	
	\item \textbf{Remuestreo} (Resampling): Las partículas son reemplazadas de manera proporcional a su nivel de importancia. Esto nos permite hacer uso del filtro de partículas solamente en situaciones en las cuales la distribución actual difiere de la propuesta. Después de aplicar este algoritmo, todas las partículas obtenidas presentan la misma importancia.
	
	\item \textbf{Estimación del mapa} (Map estimation): Para cada partícula, el  calculo del mapa estimado $ p( m^{(i)} | x_{1:t}^{(i)}, z_{1:t}) $ es realizado con base en la trayectoria $ x_{1:t}^{(i)} $ y las observaciones $ z_{1:t} $ 

\end{enumerate}
\end{mdframed}

Para que este proceso pueda ser llevado a cabo se requiere que se evalúen las ponderaciones de importancia desde cero sobre la trayectoria, cada vez que una nueva lectura este disponible, provocando que la eficiencia del algoritmo disminuya. De acuerdo a [ref] se puede obtener una fórmula para calcular de manera recursiva dicha ponderación si restringimos la distribución propuesta a una que cumpla con la siguiente suposición:

	\begin{equation}
	\label{eq:piRestriction}
		\pi (x_{1:t} | z_{1:t}, u_{1:t-1})	= 
			\pi ( x_{t} | x_{1:t-1}, z_{1:t}, u_{1:t-1}) \cdot
			\pi ( x_{1:t-1} | z_{1:t-1}, u_{1:t-2})
	\end{equation}

Con base en las ecuaciones (\ref{eq:weigth}) y (\ref{eq:piRestriction}) obtenemos que la ponderación de importancia puede ser calculada como:

	\begin{equation}
	\label{eq:weigthRecursive}
		w_{t}^{(i)} \propto
			\frac{ p( z_{t} | m_{t-1}^{(i)}, x_{t}^{(i)} ) 
			       p( x_{t}^{(i)} | x_{t-1}^{(i)}, u_{t-1} )
			 }{\pi ( x_{t} | x_{1:t-1}^{(i)}, z_{1:t}, u_{1:t-1} ) } \cdot
			 w_{t-1}^{i}
	\end{equation}
	
La cual tiene un factor de normalización:

	\begin{equation}
	\eta
		= \frac{1}{p( z_{t} | z_{1:t-1}, u_{1:t-1} )}
	\end{equation} 

\section{Filtro de partículas Rao-Blackwell (RBPF) con mejoramiento en la distribución propuesta y un proceso de remuestreo adaptable}

\subsection{Acerca de la distribución propuesta mejorada}

Como se describió anteriormente, durante la etapa de predicción se tienen que tomar muestras de una distribución propuesta $ \pi $ con el objetivo de obtener la siguiente generación de partículas.

Desafortunadamente en el contexto de SLAM no existe en general una forma cerrada de calcular la probabilidad conjunta posterior. Por lo tanto algunas de las aplicaciones comunes se hace uso del modelo de odometría como la distribución propuesta. A partir de esto el cálculo de la ponderación de importancia es hecho de acuerdo al modelo de probabilidad de observación $ p( z_{t} | m, x_{t} ) $. Esto resulta de reemplazar $ \pi $ en (\ref{eq:weigthRecursive}) y obtenemos:

	\begin{equation}
		w_{t}^{(i)} \propto
			w_{t-1}^{(i)} \cdot p( z_{t} | m_{t-1}^{(i)}, x_{t}^{(i)} )
	\end{equation}

Sin embargo esta distribución es subóptima, especialmente si se toma en cuenta que la información obtenida por el sensor láser es significativamente mas precisa que la estimación del movimiento del robot basada solamente en la odometría. 

Una estrategia común es usar una función de probabilidad suavizada, tratando de evitar que las partículas cercanas al área útil obtengan una ponderación de importancia baja.

Para evitar este problema se puede hacer uso de la última lectura obtenida por el sensor $ z_{t} $, al momento de obtener la siguiente generación de partículas. Al momento de integrar esta información la etapa de muestreo se enfoca en las áreas mas útiles del modelo de probabilidad de observación. De acuerdo a [ref] tenemos que:

	\begin{equation}
		p(x_{1:t} | m_{t-1}^{(i)}, x_{t-1}^{(i)}, z_{1:t},u_{1:t-1}) =
			\frac{p(z_{t} | m_{t-1}^{(i)}, x_{t}) p(x_{t} | x_{t-1}^{(i)}, u_{t-1}) }
			{p(z_{t} | m_{t-1}^{(i)}, x_{t-1}^{(i)}, u_{1:t-1})}
	\end{equation}

es la propuesta de distribución óptima con respecto a la varianza de la ponderación de importancia de las partículas. Con base en esta propuesta obtenemos que el cálculo de dicha ponderación se convierte en:

	\begin{equation}
		w_{t}^{(i)} = 
			w_{t-1}^{(i)} \cdot \int p(z_{t}|x') p(x' | x_{t-1}^{(i)}, u_{t-1})dx'
	\end{equation}
	
\subsection{Cálculo eficiente de distribución propuesta mejorada}

En el contexto de SLAM, el primer paso debería ser tener una muestra de las posibles poses de un robot $ x_{j} $ a partir del modelo de movimiento $ p(x_{t} | x_{t-1}^{(i)}, u_{t-1}) $. Mientras que como segundo paso se le asigne una ponderación de importancia a las partículas de acuerdo a la probabilidad de las observaciones con el objetivo de obtener una aproximación a la distribución propuesta óptima.

En la mayoría de los casos la distribución objetivo tiene un número limitado de máximos, mientras que en la mayoría solamente tiene uno. Esto nos permite obtener las posiciones $ x_{j} $ buscando que cubran solamente el área alrededor a este máximo, ignorando las área menos útiles.

En la estrategia actual se toman en cuenta ambos componentes; la probabilidad de las observaciones y el modelo de movimiento dentro del intervalo $ L^{(i)} $

Para obtener de manera eficiente la siguiente generación de partículas, se calcula una aproximación gaussiana $ \mathcal{N} $. Como primer paso se hace uso de un proceso de alineación de puntos para determinar el área mas significativa de la función de probabilidad de observación. En seguida se obtiene una muestra en el área seleccionada y se evalúan los puntos muestra con base en la distribución objetivo. Por lo tanto los parámetros gaussianos se obtienen como:

	\begin{align}
		\begin{aligned}
			\mu_{t}^{(i)} = 
				& \frac{1}{\eta^{(i)}} \cdot \sum^{K}_{j=1}  x_{j} \cdot p(z_{t}|m_{t-1}^{(i)},x_{j}) \\ 
				& \cdot p(x_{j} | x_{t-1}^{(i)}, u_{t-1})
		\end{aligned} \\
		\begin{aligned}
			\Sigma^{(i)}_{t} =
				& \frac{1}{\eta^{(i)}} \cdot \sum^{K}_{j=1} p(z_{t} | m_{t-1}^{(i)},x_{j}) \\
				& \cdot p(x_{j} | x_{t-1}^{(i)}, u_{t-1}) \\
				& \cdot (x_{j} - \mu^{(i)})(x_{j} - \mu^{(i)})^{T} 
		\end{aligned}
	\end{align}

con el siguiente factor de normalización:

	\begin{equation}
		\eta^{(i)} = \sum^{K}_{j=1} p(z_{t} | m_{t-1}^{(i)},x_{j}) \cdot
			p(x_{j} | x_{t-1}^{(i)}, u_{t-1})
	\end{equation}

Utilizando la distribución propuesta se obtiene que el cálculo de la ponderación de importancia es:

	\begin{equation}
		w_{t}^{(i)} = w_{t-1}^{(i)} \cdot \eta^{(i)}
	\end{equation}

Donde $ \eta^{(i)} $ es el mismo factor de normalización obtenido en el cálculo de la distribución gaussiana propuesta.

\subsection{Discusión sobre la distribución mejorada}

La propuesta actual toma en cuenta los datos mas recientes obtenidos tanto por el láser como el sistema de odometría mientras que al mismo tiempo permite realizar un muestreo eficiente. La densidad de las muestras resultantes tiene por lo tanto una incertidumbre mucho mas pequeña comparada con aquellas situaciones en las cuales solamente el modelo de odometría fue utilizado.

Cuando se tiene el caso que la función de probabilidad es multi-modal i.e. al momento de cerrar un circuito (close-loop) el proceso de alineación de puntos obtiene para cada partícula la probabilidad máxima, la cual es la suposición inicial.

Se debe hacer notar que aún en situaciones como cerrar un circuito, la solución planteada sigue teniendo la capacidad de mantener múltiples hipótesis debido a que la suposición inicial de la posición de cada partícula es diferentes al momento de volver a entrar a un circuito que ya se había recorrido.

El proceso de alineamiento de puntos puede llegar a fallar debido a observaciones de muy pobres o que el área de superposición de las partículas de la observación actual y la anterior sea muy pequeña. En este caso se hace uso solamente del modelo cinemático.

\subsection{Remuestreo adaptativo}

Por un lado el proceso de remuestreo es necesario ya que solamente un número finito de partículas es usado. Mientras que por el otro, al momento de realizar el remuestreo pueden quedar eliminadas buenas partículas del conjunto utilizado, causando la pérdida de información valiosa, efecto conocido como \emph{particle depletion}.

\emph{Liu} introdujo una medida para calcular que tan bien representa el conjunto de partículas actuales la probabilidad posterior. Este número es conocido como \emph{effective number of particles} $ N_{eff} $. Se calcula de la siguiente manera

\begin{equation}
	N_{eff}	= \frac{1}
		{\sum^{N}_{i=1} (w^{(i)})^{2}}
\end{equation}

Se puede deducir que dado que mientras peor sea la aproximación obtenida mayor será la varianza de la importancia de las partículas. Por lo tanto se puede proponer un límite en el valor de $N_{eff}$ en el cual se desarrolle el proceso de remuestreo. Para este trabajo se utilizó $ N/2 $ donde $ N $ es el número de partículas utilizadas.



%-------------------------------------------
% SECCION: REFERENCIAS
%-------------------------------------------



\bibliographystyle{ieeetran}
\bibliography{bibliography}

\end{document}

































